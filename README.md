# Palli Rajasekhar Reddy üëã
### Senior Data Engineer | AWS, GCP, Big Data, DevOps | 10+ Years of Experience

I am a **Data Engineer** with over 10+ years of experience working with **AWS**, **Google Cloud Platform (GCP)**, **Big Data**, and **DevOps**. My expertise spans cloud data solutions, automation, and infrastructure as code.

---

### üíº **Professional Summary**

- üåç Based in **Hyderabad, India** | Actively looking for **Remote Data Engineering** roles.
- üöÄ Strong background in **Data Engineering**, **Cloud Solutions**, and **Big Data**.
- üîß Skilled in **AWS**(Glue, EMR, Redshift, Lambda, Step Functions, S3, EC2, ECS, Cloud Formation, SAM, EventBridge and IAM), **GCP**(BigQuery, DataFlow, Dataproc, GCS, Pub/Sub, CloudRun, CloudBatch, Workflows and DeploymentManager), **Terraform**, **Airflow**, **Snowflake**, **SQL**,  **Python**, and **Talend**.
- üåê Passionate about building **automated data pipelines** and implementing **DevOps** in cloud environments.

---

### üî® **Key Skills and Expertise**
- **AWS Services**: Extensive use of AWS Glue, S3, Lambda, EC2, EMR, Step Functions, and CloudFormation to manage data pipelines and cloud infrastructure.
- Built scalable **ETL pipelines** using **AWS Glue** and automated workflows using **Step Functions** and **Lambda** functions for event-driven architectures.
- Automated **infrastructure provisioning** and deployment using **Terraform** and **AWS CloudFormation**, ensuring robust and repeatable deployments.
- Managed high-throughput data pipelines on **AWS EMR** for Big Data processing with **Apache Spark** and **Hadoop**.
- Integrated **Jenkins** for CI/CD pipelines with AWS services, enabling automated deployments and testing.
- Used **Talend** for data migration tasks from on-premise systems to **AWS S3** and **GCS**.
- Leveraged **Amazon RDS** and **Redshift** for data warehousing solutions, optimizing data storage and query performance.
- Developed **data processing pipelines** on **GCP** using **Dataflow**, automating the orchestration with **Cloud Composer (Airflow)**.
- Migrated on-premise data workloads to **GCP** using **BigQuery**, integrating **GCS** and **Dataflow** for real-time data processing.
- Designed partitioning and clustering strategies for optimized querying in **BigQuery**, reducing costs and improving efficiency.
- Implemented **CI/CD** with **Terraform** to manage **GCP infrastructure**, ensuring secure and scalable environments.
- Worked with **Cloud Functions** and **Pub/Sub** for event-driven architectures on **GCP**, building real-time data ingestion systems.
- Hands-on experience in designing and maintaining **Airflow** DAGs for complex data workflows in both AWS and GCP environments.
- Deployed **DBT** for efficient management and transformation of SQL models in **Snowflake** and **BigQuery**.
- Orchestrated ETL jobs using **Airflow** and **AWS Glue**, improving data quality and reducing manual intervention.
- Implemented **security best practices** for cloud infrastructure and data pipelines using IAM roles, VPCs, and KMS encryption.
- Developed **Python-based ETL jobs** to clean, transform, and analyze large datasets in cloud environments.
- Processed large-scale, multi-format data using **PySpark** on **AWS EMR** and **GCP Dataflow**.
- Experience with **containerizing applications** using **Docker** to ensure environment consistency and portability.
- Automated **end-to-end data pipelines** with **Terraform** to deploy data infrastructure in both **AWS** and **GCP**.
- Leveraged **Amazon Kinesis** and **AWS Lambda** for real-time streaming applications, ensuring high scalability and low latency.
- Designed and optimized **data warehouse solutions** using **Snowflake**, improving performance for analytical workloads.
- Extensive work with **data lake architectures** on **AWS S3** and **GCP Cloud Storage** for efficient data storage and retrieval.
- Migrated legacy systems and on-premise workloads to **AWS** and **GCP**, reducing operational costs and improving scalability.
- Created and monitored **data validation checks** for ETL pipelines, improving data integrity and reducing errors.
- Worked with **Jenkins**, **Git**, and **Terraform** for version control, CI/CD, and infrastructure as code across multiple cloud environments.
- Expertise in **Python scripting** to automate data extraction, cleaning, and loading into cloud data warehouses like **BigQuery** and **Redshift**.
- Used **Hadoop** and **Apache Spark** for batch data processing, enabling distributed computing for large datasets.
- Integrated **Snowflake** with **AWS S3** for real-time data ingestion, managing multi-terabyte scale data efficiently.
- Experience with **Kafka** and **Pub/Sub** for message-driven architectures in distributed systems.
- Designed **AWS Glue workflows** for automating the transformation and movement of data between different AWS services.
- Experience in working with **Terraform modules** to standardize infrastructure provisioning across projects.
- Implemented **data governance** practices using **AWS Lake Formation** and **Snowflake**, ensuring data security and compliance.
- Developed **Airflow DAGs** to manage dependencies between multiple ETL jobs, improving overall pipeline reliability.
- Tuned **Spark** jobs for optimal memory management and processing speed in large-scale distributed environments.
- Monitored and optimized query performance in **Snowflake** and **BigQuery** by adjusting partitioning, clustering, and indexing strategies.
- Automated testing and validation of infrastructure using **Terratest** and integrated it with **Jenkins** for end-to-end CI/CD.
- Experience in multi-cloud solutions, integrating AWS and GCP services to leverage the strengths of both platforms.
- Hands-on experience with **data replication** between on-premise and cloud environments for real-time analytics and disaster recovery.
- Built **batch and stream processing systems** using **Apache Spark** on **GCP Dataproc** and **AWS EMR**.

---

### üõ† **Technologies & Tools**
- **Cloud Platforms**: AWS (Glue, EMR, Redshift, Lambda, Step Functions, S3, EC2, ECS, Cloud Formation, SAM, EventBridge and IAM), GCP (BigQuery, DataFlow, Cloud Composer, Dataproc, GCS, Pub/Sub, CloudRun, CloudBatch, Workflows and DeploymentManager), Snowflake
- **Languages**: Python, SQL, PySpark, Bash
- **DevOps & CI/CD**: Terraform, Jenkins, Docker, Git, CloudFormation
- **Big Data**: Apache Spark, Hadoop, EMR, Dataproc, HDFS
- **Data Orchestration**: Airflow, Step Functions, AWS Glue, Cloud Composer (Airflow)
- **ETL Tools**: Talend, DBT
- **Data Warehousing**: Snowflake, BigQuery, Redshift, RDS

---

### üì´ **Get In Touch**
- **LinkedIn**: [rajasekhar-reddy-palli](https://www.linkedin.com/in/rajasekhar-reddy-palli)
- **Email**: [rajashekarreddy.it@gmail.com](mailto:rajashekarreddy.it@gmail.com)
- **Mobile**: [+91 944 174 6584](tel:+919441746584)

Feel free to explore my repositories or connect with me for collaboration on **cloud-native data engineering** projects!
